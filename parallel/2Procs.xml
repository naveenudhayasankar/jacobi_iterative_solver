<?xml version="1.0" encoding="iso-8859-1"?>
<ipm_job_profile>
<calltable nsections="1" >
<section module="MPI" nentries="69" >
<entry name="MPI_Init" />
<entry name="MPI_Init_thread" />
<entry name="MPI_Finalize" />
<entry name="MPI_Comm_rank" />
<entry name="MPI_Comm_size" />
<entry name="MPI_Send" />
<entry name="MPI_Ssend" />
<entry name="MPI_Rsend" />
<entry name="MPI_Bsend" />
<entry name="MPI_Isend" />
<entry name="MPI_Issend" />
<entry name="MPI_Irsend" />
<entry name="MPI_Ibsend" />
<entry name="MPI_Recv" />
<entry name="MPI_Irecv" />
<entry name="MPI_Sendrecv" />
<entry name="MPI_Sendrecv_replace" />
<entry name="MPI_Wait" />
<entry name="MPI_Waitany" />
<entry name="MPI_Waitall" />
<entry name="MPI_Waitsome" />
<entry name="MPI_Probe" />
<entry name="MPI_Iprobe" />
<entry name="MPI_Send_init" />
<entry name="MPI_Ssend_init" />
<entry name="MPI_Rsend_init" />
<entry name="MPI_Bsend_init" />
<entry name="MPI_Recv_init" />
<entry name="MPI_Buffer_attach" />
<entry name="MPI_Buffer_detach" />
<entry name="MPI_Test" />
<entry name="MPI_Testany" />
<entry name="MPI_Testall" />
<entry name="MPI_Testsome" />
<entry name="MPI_Start" />
<entry name="MPI_Startall" />
<entry name="MPI_Bcast" />
<entry name="MPI_Reduce" />
<entry name="MPI_Reduce_scatter" />
<entry name="MPI_Barrier" />
<entry name="MPI_Gather" />
<entry name="MPI_Gatherv" />
<entry name="MPI_Scatter" />
<entry name="MPI_Scatterv" />
<entry name="MPI_Scan" />
<entry name="MPI_Allgather" />
<entry name="MPI_Allgatherv" />
<entry name="MPI_Allreduce" />
<entry name="MPI_Alltoall" />
<entry name="MPI_Alltoallv" />
<entry name="MPI_Comm_group" />
<entry name="MPI_Comm_compare" />
<entry name="MPI_Comm_dup" />
<entry name="MPI_Comm_create" />
<entry name="MPI_Comm_split" />
<entry name="MPI_Comm_free" />
<entry name="MPI_Ibcast" />
<entry name="MPI_Ireduce" />
<entry name="MPI_Ireduce_scatter" />
<entry name="MPI_Igather" />
<entry name="MPI_Igatherv" />
<entry name="MPI_Iscatter" />
<entry name="MPI_Iscatterv" />
<entry name="MPI_Iscan" />
<entry name="MPI_Iallgather" />
<entry name="MPI_Iallgatherv" />
<entry name="MPI_Iallreduce" />
<entry name="MPI_Ialltoall" />
<entry name="MPI_Ialltoallv" />
</section>
</calltable>
<task ipm_version="2.0.6" cookie="nocookie" mpi_rank="0" mpi_size="2" stamp_init="1670306380.261199" stamp_final="1670307591.377829" username="naveen" allocationname="unknown" flags="0" pid="32041" >
<job nhosts="1" ntasks="2" start="1670306380" final="1670307591" cookie="nocookie" code="unknown" >unknown</job>
<host mach_name="x86_64" mach_info="x86_64_Linux" >naveen-VirtualB</host>
<perf wtime="1.21112e+03" utime="9.69315e+01" stime="2.39334e+00" mtime="1.17236e+03" gflop="0.00000e+00" gbyte="5.57861e-02" omp_num_threads="1"></perf>
<modules nmod="1">
<module name="MPI" time="1.17236e+03" ></module>
</modules>
<switch bytes_tx="0.00000e+00" bytes_rx="0.00000e+00" ></switch>
<cmdline realpath="/home/naveen/cse708/jacobi_iteration/parallel/mpi_jacobi" md5sum="c3b4f4320000b17fb17fb17fe056b17f8b" >./mpi_jacobi 1000 </cmdline>
<regions n="1" >
<region label="ipm_noregion" nexits="1" wtime="1.21111e+03" utime="9.69279e+01" stime="2.39333e+00" mtime="1.17236e+03" id="0">
<modules nmod="1">
<module name="MPI" time="1.17236e+03" ></module>
</modules>
<func name="MPI_Init" count="1" bytes="0.0000e+00" > 0.0000e+00 </func>
<func name="MPI_Finalize" count="1" bytes="0.0000e+00" > 0.0000e+00 </func>
<func name="MPI_Comm_rank" count="1" bytes="0.0000e+00" > 9.5367e-07 </func>
<func name="MPI_Comm_size" count="1" bytes="0.0000e+00" > 1.1921e-06 </func>
<func name="MPI_Allgather" count="18200" bytes="3.2687e+07" > 1.1724e+03 </func>
</region>
</regions>
<internal rank="0" log_i="1670307591.377829" log_t="1.6703e+09" report_delta="-1.0000e+00" fname="./naveen.1670306380.261199.ipm.xml" logrank="0" ></internal>
</task>
<task ipm_version="2.0.6" cookie="nocookie" mpi_rank="1" mpi_size="2" stamp_init="1670306380.296571" stamp_final="1670307591.483999" username="naveen" allocationname="unknown" flags="0" pid="32042" >
<job nhosts="1" ntasks="2" start="1670306380" final="1670307591" cookie="nocookie" code="unknown" >unknown</job>
<host mach_name="x86_64" mach_info="x86_64_Linux" >naveen-VirtualB</host>
<perf wtime="1.21119e+03" utime="9.70492e+01" stime="2.27657e+00" mtime="1.17186e+03" gflop="0.00000e+00" gbyte="5.57861e-02" omp_num_threads="1"></perf>
<modules nmod="1">
<module name="MPI" time="1.17236e+03" ></module>
</modules>
<switch bytes_tx="0.00000e+00" bytes_rx="0.00000e+00" ></switch>
<cmdline realpath="/home/naveen/cse708/jacobi_iteration/parallel/mpi_jacobi" md5sum="c3b4f4320000997f997f997f7f56997fd8" >./mpi_jacobi 1000 </cmdline>
<regions n="1" >
<region label="ipm_noregion" nexits="1" wtime="1.21118e+03" utime="9.70458e+01" stime="2.27656e+00" mtime="1.17186e+03" id="0">
<modules nmod="1">
<module name="MPI" time="1.17236e+03" ></module>
</modules>
<func name="MPI_Init" count="1" bytes="0.0000e+00" > 0.0000e+00 </func>
<func name="MPI_Finalize" count="1" bytes="0.0000e+00" > 0.0000e+00 </func>
<func name="MPI_Comm_rank" count="1" bytes="0.0000e+00" > 2.1458e-06 </func>
<func name="MPI_Comm_size" count="1" bytes="0.0000e+00" > 9.5367e-07 </func>
<func name="MPI_Allgather" count="18200" bytes="3.2687e+07" > 1.1719e+03 </func>
</region>
</regions>
<internal rank="1" log_i="1670307591.483999" log_t="1.6703e+09" report_delta="-1.0000e+00" fname="./naveen.1670306380.261199.ipm.xml" logrank="0" ></internal>
</task>
</ipm_job_profile>
